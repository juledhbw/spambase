{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, make_scorer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark bei nicht modifizierter Anwendung von XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare X as the predictor columns and y as the target column, where the\n",
    "last row is the target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spambase.data', header=None)\n",
    "Y=df[57]\n",
    "X=df.drop([57],axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize XGBClassifier with the booster='gbtree' and\n",
    "objective='binary:logistic' defaults along with\n",
    "random_state=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [95.22 94.67 95.22 97.39 83.26]\n",
      "Accuracy mean: 93.15\n",
      "---\n",
      "Precision: [95.44 95.64 92.76 97.47 74.76]\n",
      "Precision mean: 91.22\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "scores = cross_validate(model, X, Y, cv=5, scoring=scorers)\n",
    "\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "precision_scores = scores['test_precision']\n",
    "\n",
    "print('Accuracy:', np.round(scores['test_accuracy']*100, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores['test_accuracy'].mean()*100))\n",
    "print('---')\n",
    "print('Precision:', np.round(scores['test_precision']*100, 2))\n",
    "print('Precision mean: %0.2f' % (scores['test_precision'].mean()*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark bei Verwendung von modifizierten Datensätzen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen der vorbereiteten Datensätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('selected_data_44.csv', header=None)\n",
    "Y=df[45]\n",
    "X=df.drop([45],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [ 69.71 100.   100.   100.    80.33]\n",
      "Accuracy mean: 90.01\n",
      "---\n",
      "Precision: [ 56.54 100.   100.   100.   100.  ]\n",
      "Precision mean: 91.31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "scores = cross_validate(model, X, Y, cv=5, scoring=scorers)\n",
    "\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "precision_scores = scores['test_precision']\n",
    "\n",
    "print('Accuracy:', np.round(scores['test_accuracy']*100, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores['test_accuracy'].mean()*100))\n",
    "print('---')\n",
    "print('Precision:', np.round(scores['test_precision']*100, 2))\n",
    "print('Precision mean: %0.2f' % (scores['test_precision'].mean()*100))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark bei modifizierter Anwendung von XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spambase.data', header=None)\n",
    "Y=df[57]\n",
    "X=df.drop([57],axis=1)\n",
    "\n",
    "model = XGBClassifier(random_state=2, n_estimators=500, learning_rate= 0.03, max_depth=2, colsample_bytree=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [95.77 94.13 95.54 96.85 85.  ]\n",
      "Accuracy mean: 93.46\n",
      "---\n",
      "Precision: [96.02 96.68 94.48 98.54 77.59]\n",
      "Precision mean: 92.66\n"
     ]
    }
   ],
   "source": [
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "scores = cross_validate(model, X, Y, cv=5, scoring=scorers)\n",
    "\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "precision_scores = scores['test_precision']\n",
    "\n",
    "print('Accuracy:', np.round(scores['test_accuracy']*100, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores['test_accuracy'].mean()*100))\n",
    "print('---')\n",
    "print('Precision:', np.round(scores['test_precision']*100, 2))\n",
    "print('Precision mean: %0.2f' % (scores['test_precision'].mean()*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark bei modifizierter Anwendung von XGBoost und modifizierter Daten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [94.46 98.59 99.02 99.67 91.2 ]\n",
      "Accuracy mean: 96.59\n",
      "---\n",
      "Precision: [89.59 98.88 98.63 99.72 94.04]\n",
      "Precision mean: 96.17\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('selected_data_44.csv', header=None)\n",
    "Y=df[45]\n",
    "X=df.drop([45],axis=1)\n",
    "\n",
    "model = XGBClassifier(random_state=2, n_estimators=100, learning_rate= 0.03, max_depth=8, colsample_bytree=0.3 )\n",
    "\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "scores = cross_validate(model, X, Y, cv=5, scoring=scorers)\n",
    "\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "precision_scores = scores['test_precision']\n",
    "\n",
    "print('Accuracy:', np.round(scores['test_accuracy']*100, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores['test_accuracy'].mean()*100))\n",
    "print('---')\n",
    "print('Precision:', np.round(scores['test_precision']*100, 2))\n",
    "print('Precision mean: %0.2f' % (scores['test_precision'].mean()*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [90.88 99.46 99.46 99.89 92.17]\n",
      "Accuracy mean: 96.37\n",
      "---\n",
      "Precision: [81.92 98.91 98.91 99.72 97.08]\n",
      "Precision mean: 95.31\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('selected_data_37.csv', header=None)\n",
    "Y=df[38]\n",
    "X=df.drop([38],axis=1)\n",
    "\n",
    "model = XGBClassifier(random_state=2, n_estimators=100, learning_rate= 0.06, max_depth=8, colsample_bytree=0.3)\n",
    "\n",
    "scorers = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score)\n",
    "}\n",
    "\n",
    "scores = cross_validate(model, X, Y, cv=5, scoring=scorers)\n",
    "\n",
    "accuracy_scores = scores['test_accuracy']\n",
    "precision_scores = scores['test_precision']\n",
    "\n",
    "print('Accuracy:', np.round(scores['test_accuracy']*100, 2))\n",
    "print('Accuracy mean: %0.2f' % (scores['test_accuracy'].mean()*100))\n",
    "print('---')\n",
    "print('Precision:', np.round(scores['test_precision']*100, 2))\n",
    "print('Precision mean: %0.2f' % (scores['test_precision'].mean()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
